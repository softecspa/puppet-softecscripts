#!/usr/bin/env python

"""Copia gli archivi di AutoMysqlBackup su S3.

Uso:
    s3sync.py -c pys3sync.conf
    s3sync.py -c pys3sync.conf -n
    s3sync.py -c pys3sync.conf --pattern='^backup_Cluster(Asp|Dev)$'
"""

import os
import sys

libpath = '/usr/local/lib/softec-python'

try:
    sys.path.insert(0, os.path.realpath(os.environ['MYLIBDIR']))
except KeyError:
    sys.path.insert(0, libpath)

try:
    import argparse
    import boto
    import libconfigparser2 as configparser
    import libsh as sh
    import sys
    import datetime
    import libsendnsca as sendnsca
    from libutils import human_time, str_join, to_stderr, to_stdout
except ImportError as e:
    raise sys.exit('Import Error: %s' % e)

# import glob
import time

__version__ = '0.1'
__author__ = 'Lorenzo Cocchi <lorenzo.cocchi@softecspa.it>'


def parse_argv():
    desc = 'Python sync MySQL backup to S3'
    parsearg = argparse.ArgumentParser(description=desc)

    parsearg.add_argument(
        '-c', '--config', action='store', dest='config',
        help='config file, default /usr/local/etc/pys3sync.conf',
        type=str, default='/usr/local/etc/s3sync.conf')

    parsearg.add_argument(
        '-p', '--pattern', action='store', dest='pattern',
        help="regexp for [section], default \'^backup_.+\'",
        type=str, default='^backup_.+')

    parsearg.add_argument(
        '-n', '--dry-run', action='store_true', dest='dryrun',
        help='dryrun mode')

    parsearg.add_argument(
        '-v', '--verbose', action='store_true', dest='verbose',
        help='verbose')

    parsearg.add_argument(
        '-s', '--sleep', action='store', dest='timesleep',
        help='sleep between iterations, default 10s', type=int, default=10)

    parsearg.add_argument(
        '-t', '--sync-times', action='store', dest='sync_times',
        help='try syncing multiple times, default 3', type=int, default=3)

    parsearg.add_argument(
        '-V', '--version', action='version',
        version='%(prog)s ' + __version__)

    return parsearg.parse_args()


def main():
    args = parse_argv()
    (config,
     pattern,
     dryrun,
     timesleep,
     verbose,
     sync_times) = (args.config,
                    args.pattern,
                    args.dryrun,
                    args.timesleep,
                    args.verbose,
                    args.sync_times)

    if sync_times < 0 and sync_times > 3:
        sys.exit('--try-sync-times must be between 0 and 3')

    try:
        parser = configparser.Parser(config)
    except (configparser.ParserError) as e:
        sys.exit('%s' % e)

    s3cmd = 's3cmd -v' if verbose is True else 's3cmd'
    s3cmd = ('%s -n' % (s3cmd)) if dryrun is True else s3cmd
    s3cmd_opts = ('sync --no-progress -H')
    s3cmd = ('%s %s' % (s3cmd, s3cmd_opts))

    # boto
    s3 = boto.connect_s3()

    # notifiche al Nagios
    global_nsca = parser.get_dict(parser.get_sections(pattern='^nsca$')[0])

    (nsca_nagios_host, nsca_cmd) = (global_nsca['nsca_nagios_host'],
                                    global_nsca['nsca_cmd'])

    try:
        nsca = sendnsca.SendNsca(nsca_nagios_host, nsca_cmd)
    except OSError as e:
        sys.exit(e)

    # sezioni
    sections = parser.get_sections(pattern=pattern)

    # variabili dalle sezioni, iterazione e nsca
    for section in sections:
        d = parser.get_dict(section)
        (desc,
         path,
         period,
         bucket,
         folder) = (d['desc'],
                    d['backup_path'],
                    d['backup_period'],
                    d['s3bucket'],
                    d['s3folder'],)

        (nsca_svc_host,
         nsca_svc_desc) = (d['nsca_svc_host'],
                           d['nsca_svc_desc'])

        # inizio
        to_stdout('= %s - %s starting =' % (desc, time.ctime(time.time())))

        # costruzione del bucket_name per s3cmd
        s3bucket = 's3://%s' % (bucket)

        # se non esiste il bucket prova a crearlo
        if s3.lookup(bucket) is None:
            try:
                s3.create_bucket(bucket)
                to_stdout('Create bucket %s' % bucket)
            except (boto.exception.S3ResponseError,
                    boto.exception.S3CreateError) as e:
                msg = ('Failed create_bucket(%s): %s %s, %s' %
                       (bucket, e.status, e.reason, e.error_code))
                to_stderr(msg)
                nsca.service_result(nsca_svc_host, nsca_svc_desc, 2, msg)
                continue

        # desfinizione del bucket di destinazione
        today = datetime.datetime.today().strftime('%Y/%m/%d')
        if folder:
            s3path = ('%s/%s/%s/' % (s3bucket, folder, today))
        else:
            s3path = ('%s/%s/' % (s3bucket, today))

        path = os.path.join(path, period.strip())

        # check sul PATH locale, se no lo trova continua l'iterazione
        if os.path.exists(path):
            path = ('%s/' % path)
        else:
            msg = ('No such file or directory: %s' % path)
            to_stderr(msg)
            nsca.service_result(nsca_svc_host, nsca_svc_desc, 2, msg)
            continue

        # processiamo i singoli elementi, in questo modo siamo abbiamo piu'
        #  velocita' su directory con un numero elevato di elementi
        # items = glob.glob('%s/%s' % (path, '*'))

        to_stdout('== S3 bucket "%s" ==' % bucket)
        start_time = time.time()

        # sync degli elementi sul bucket su S3, ci prova N volte
        to_stdout('== Sync %s to %s ==' % (path, s3path))
        sync_ok = False

        for count in range(0, sync_times):
            if verbose is True:
                to_stdout(str_join(s3cmd, path, s3path))

            s_out, s_err = sh.run(str_join(s3cmd, path, s3path))[:2]
            if s_err:
                to_stderr('Sync (try=%s) %s to %s: %s' % (count,
                                                          path,
                                                          s3path,
                                                          s_err))
                if s_out:
                    to_stdout(s_out)

                time.sleep(5)
                continue
            else:
                if s_out or not s_err:
                    to_stdout(s_out)
                    sync_ok = True
                break

        date_now = ('%s' % datetime.datetime.now())
        if sync_ok is not True:
            msg_err = ('%s: errors' % date_now)
            nsca.service_result(nsca_svc_host, nsca_svc_desc, 2, msg_err)

        if sync_ok is True:
            msg_ok = ('%s: successfully' % date_now)
            nsca.service_result(nsca_svc_host, nsca_svc_desc, 0, msg_ok)

        end_time = time.time()
        to_stdout('Completed in %s' % human_time((end_time - start_time)))
        to_stdout('Sleep %ss\n' % (timesleep))
        time.sleep(timesleep)


if __name__ == '__main__':
    main()
